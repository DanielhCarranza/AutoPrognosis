{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoPrognosis API Tutorial\n",
    "\n",
    "A demonstration for AP functionality and operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows how to use [Autoprognosis](https://arxiv.org/abs/1802.07207). We are using the UCI ML Breast Cancer Wisconsin (Diagnostic) dataset.\n",
    "\n",
    "See [installation instructions](../../doc/install.md) to install the dependencies.\n",
    "\n",
    "Load dataset and show the first five samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension   ...    worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871   ...            17.33           184.60      2019.0   \n",
       "1                 0.05667   ...            23.41           158.80      1956.0   \n",
       "2                 0.05999   ...            25.53           152.50      1709.0   \n",
       "3                 0.09744   ...            26.50            98.87       567.7   \n",
       "4                 0.05883   ...            16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "data = load_breast_cancer()  # get Breast Cancer Dataset\n",
    "\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names) # create pandas dataframe\n",
    "target = 'target'\n",
    "df[target] = data.target\n",
    "\n",
    "\n",
    "X_ = df[data.feature_names]\n",
    "Y_ = df[target]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the AutoPrognosis library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model with few iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ median, Normalization, Gradient Boosting ]\n",
      "[ mean, Gaussian Transformer, MultinomialNaiveBayes ]\n",
      "[ missForest, Uniform Transformer, LinearSVM ]\n",
      "[ mean, Gradient Boosting ]\n",
      "[ missForest, PCA, MultinomialNaiveBayes ]\n",
      "[ matrix_completion, PCA, GaussianNaiveBayes ]\n",
      "[ matrix_completion, PCA, XGBoost ]\n",
      "[ missForest, Gaussian random projections, BernoullinNaiveBayes ]\n",
      "[ median, GaussianNaiveBayes ]\n",
      "[ missForest, Normalization, Random Forest ]\n",
      "[ median, Bagging ]\n",
      "[ mean, Gaussian Transformer, GaussianNaiveBayes ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**The best model is: **[ missForest, PCA, Bagging ]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       " |||| Now building the ensemble..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Ensemble: **['[ median, Bagging ]', '[ median, Normalization, GaussianNaiveBayes ]', '[ matrix_completion, Gaussian random projections, Random Forest ]']"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Ensemble weights: **[0.50139696 0.14415384 0.3544492 ]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**The ensemble helps!**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'aucprc': 0.9810585834962593, 'name': 'initial'},\n",
       " {'aucprc': 0.9881686666304725,\n",
       "  'aucroc': 0.987389452997052,\n",
       "  'component_idx': 0,\n",
       "  'cv': 5,\n",
       "  'hyperparameter_properties': [{'name': 'mean'},\n",
       "   {'hyperparameters': {'model': \"GradientBoostingClassifier(criterion='friedman_mse', init=None,\\n                           learning_rate=0.2140593364154549, loss='deviance',\\n                           max_depth=5, max_features=None, max_leaf_nodes=None,\\n                           min_impurity_decrease=0.0, min_impurity_split=None,\\n                           min_samples_leaf=1, min_samples_split=2,\\n                           min_weight_fraction_leaf=0.0, n_estimators=137,\\n                           n_iter_no_change=None, presort='auto',\\n                           random_state=None, subsample=1.0, tol=0.0001,\\n                           validation_fraction=0.1, verbose=0,\\n                           warm_start=False)\"},\n",
       "    'name': 'Gradient Boosting'}],\n",
       "  'iter': 0,\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x000001E4383869E8>',\n",
       "  'name': '[ mean, Gradient Boosting ]'},\n",
       " {'aucprc': 0.45856070121400183,\n",
       "  'aucroc': 0.1662413759040028,\n",
       "  'component_idx': 1,\n",
       "  'cv': 5,\n",
       "  'hyperparameter_properties': [{'name': 'missForest'},\n",
       "   {'name': 'PCA'},\n",
       "   {'hyperparameters': {'model': 'MultinomialNB(alpha=4.222417436498645, class_prior=None, fit_prior=True)'},\n",
       "    'name': 'MultinomialNaiveBayes'}],\n",
       "  'iter': 0,\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x000001E4326F5F60>',\n",
       "  'name': '[ missForest, PCA, MultinomialNaiveBayes ]'},\n",
       " {'aucprc': 0.5820764749237813,\n",
       "  'aucroc': 0.5057915971279876,\n",
       "  'component_idx': 2,\n",
       "  'cv': 5,\n",
       "  'hyperparameter_properties': [{'name': 'matrix_completion'},\n",
       "   {'name': 'PCA'},\n",
       "   {'hyperparameters': {'model': 'GaussianNB(priors=None, var_smoothing=1e-09)'},\n",
       "    'name': 'GaussianNaiveBayes'}],\n",
       "  'iter': 0,\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x000001E43838CD30>',\n",
       "  'name': '[ matrix_completion, PCA, GaussianNaiveBayes ]'},\n",
       " {'aucprc': 0.9588548307519804,\n",
       "  'aucroc': 0.9430387882852672,\n",
       "  'component_idx': 0,\n",
       "  'cv': 5,\n",
       "  'hyperparameter_properties': [{'name': 'matrix_completion'},\n",
       "   {'name': 'PCA'},\n",
       "   {'hyperparameters': {'model': \"XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\\n              colsample_bynode=1, colsample_bytree=1, gamma=0,\\n              learning_rate=0.08159074159980231, max_delta_step=0, max_depth=9,\\n              min_child_weight=1, missing=None, n_estimators=23, n_jobs=1,\\n              nthread=None, objective='binary:logistic', random_state=0,\\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\\n              silent=None, subsample=1, verbosity=1)\"},\n",
       "    'name': 'XGBoost'}],\n",
       "  'iter': 1,\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x000001E4387CE898>',\n",
       "  'name': '[ matrix_completion, PCA, XGBoost ]'},\n",
       " {'aucprc': 0.6554068087881467,\n",
       "  'aucroc': 0.5443326626425218,\n",
       "  'component_idx': 1,\n",
       "  'cv': 5,\n",
       "  'hyperparameter_properties': [{'name': 'missForest'},\n",
       "   {'name': 'Gaussian random projections'},\n",
       "   {'hyperparameters': {'model': 'BernoulliNB(alpha=2.3900613663771137, binarize=0.0, class_prior=None,\\n            fit_prior=True)'},\n",
       "    'name': 'BernoullinNaiveBayes'}],\n",
       "  'iter': 1,\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x000001E4387D9160>',\n",
       "  'name': '[ missForest, Gaussian random projections, BernoullinNaiveBayes ]'},\n",
       " {'aucprc': 0.9928208042301948,\n",
       "  'aucroc': 0.9872499857023277,\n",
       "  'component_idx': 2,\n",
       "  'cv': 5,\n",
       "  'hyperparameter_properties': [{'name': 'median'},\n",
       "   {'hyperparameters': {'model': 'GaussianNB(priors=None, var_smoothing=1e-09)'},\n",
       "    'name': 'GaussianNaiveBayes'}],\n",
       "  'iter': 1,\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x000001E4380865C0>',\n",
       "  'name': '[ median, GaussianNaiveBayes ]'},\n",
       " {'aucprc': 0.9926393290340083,\n",
       "  'aucroc': 0.9899113024399627,\n",
       "  'component_idx': 0,\n",
       "  'cv': 5,\n",
       "  'hyperparameter_properties': [{'name': 'missForest'},\n",
       "   {'name': 'Normalization'},\n",
       "   {'hyperparameters': {'model': \"RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\\n                       max_depth=None, max_features='auto', max_leaf_nodes=None,\\n                       min_impurity_decrease=0.0, min_impurity_split=None,\\n                       min_samples_leaf=1, min_samples_split=2,\\n                       min_weight_fraction_leaf=0.0, n_estimators=576,\\n                       n_jobs=None, oob_score=False, random_state=None,\\n                       verbose=0, warm_start=False)\"},\n",
       "    'name': 'Random Forest'}],\n",
       "  'iter': 2,\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x000001E4387B7978>',\n",
       "  'name': '[ missForest, Normalization, Random Forest ]'},\n",
       " {'aucprc': 0.993040805691102,\n",
       "  'aucroc': 0.9894163430193565,\n",
       "  'component_idx': 1,\n",
       "  'cv': 5,\n",
       "  'hyperparameter_properties': [{'name': 'median'},\n",
       "   {'hyperparameters': {'model': 'BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\\n                  max_features=1.0, max_samples=0.1378951280696428,\\n                  n_estimators=4080, n_jobs=None, oob_score=False,\\n                  random_state=None, verbose=0, warm_start=False)'},\n",
       "    'name': 'Bagging'}],\n",
       "  'iter': 2,\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x000001E432667780>',\n",
       "  'name': '[ median, Bagging ]'},\n",
       " {'aucprc': 0.9547924408028121,\n",
       "  'aucroc': 0.9419909638710818,\n",
       "  'component_idx': 2,\n",
       "  'cv': 5,\n",
       "  'hyperparameter_properties': [{'name': 'mean'},\n",
       "   {'name': 'Gaussian Transformer'},\n",
       "   {'hyperparameters': {'model': 'GaussianNB(priors=None, var_smoothing=1e-09)'},\n",
       "    'name': 'GaussianNaiveBayes'}],\n",
       "  'iter': 2,\n",
       "  'model': '<pipelines.basePipeline.basePipeline object at 0x000001E43808A358>',\n",
       "  'name': '[ mean, Gaussian Transformer, GaussianNaiveBayes ]'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = 'aucprc'\n",
    "\n",
    "AP_mdl   = model.AutoPrognosis_Classifier(\n",
    "    metric=metric, CV=5, num_iter=3, kernel_freq=100, ensemble=True,\n",
    "    ensemble_size=3, Gibbs_iter=100, burn_in=50, num_components=3)\n",
    "\n",
    "AP_mdl.fit(X_, Y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ~~~First element in the output is the predictions of a single model, the second element is the prediction of the ensemble~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.        , 0.        ],\n",
       "        [0.99803922, 0.00196078],\n",
       "        [0.99681373, 0.00318627],\n",
       "        ...,\n",
       "        [0.975     , 0.025     ],\n",
       "        [0.99730392, 0.00269608],\n",
       "        [0.22107843, 0.77892157]]), array([[1.        , 0.        ],\n",
       "        [0.99803922, 0.00196078],\n",
       "        [0.99681373, 0.00318627],\n",
       "        ...,\n",
       "        [0.975     , 0.025     ],\n",
       "        [0.99730392, 0.00269608],\n",
       "        [0.22107843, 0.77892157]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP_mdl.predict(X_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"pivottablejs.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1e42a0df2e8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP_mdl.visualize_data(X_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\r",
       "***Ensemble Report***"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**----------------------**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Rank0:   [ median, Bagging ],   Ensemble weight: 0.5013969581075489**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**----------------------**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_list': [<models.imputers.median object at 0x000001E438644A58>, <models.classifiers.Bagging object at 0x000001E4386480B8>], 'explained': '[ , *Bootstrap aggregating, also called bagging, is a machine learning ensemble meta-algorithm designed to improve the stability and accuracy of machine learning algorithms used in statistical classification and regression. It also reduces variance and helps to avoid overfitting. Although it is usually applied to decision tree methods, it can be used with any type of method. Bagging is a special case of the model averaging approach.* ]', 'image_name': None, 'classes': None, 'num_stages': 2, 'pipeline_stages': ['imputer', 'classifier'], 'name': '[ median, Bagging ]', 'analysis_mode': None, 'analysis_type': None}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**_____________________________________________**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "[ , *Bootstrap aggregating, also called bagging, is a machine learning ensemble meta-algorithm designed to improve the stability and accuracy of machine learning algorithms used in statistical classification and regression. It also reduces variance and helps to avoid overfitting. Although it is usually applied to decision tree methods, it can be used with any type of method. Bagging is a special case of the model averaging approach.* ]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning:no image_name\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Rank1:   [ median, Normalization, GaussianNaiveBayes ],   Ensemble weight: 0.14415383748272464**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**----------------------**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_list': [<models.imputers.median object at 0x000001E4386444A8>, <models.preprocessors.FeatureNormalizer object at 0x000001E4386441D0>, <models.classifiers.GaussNaiveBayes object at 0x000001E43863DDD8>], 'explained': '[ , , *A Naive Bayes classifiers are a family of simple probabilistic classifiers based on applying Bayes theorem with strong (naive) independence assumptions between the features.* ]', 'image_name': None, 'classes': None, 'num_stages': 3, 'pipeline_stages': ['imputer', 'preprocessor', 'classifier'], 'name': '[ median, Normalization, GaussianNaiveBayes ]', 'analysis_mode': None, 'analysis_type': None}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**_____________________________________________**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "[ , , *A Naive Bayes classifiers are a family of simple probabilistic classifiers based on applying Bayes theorem with strong (naive) independence assumptions between the features.* ]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning:no image_name\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Rank2:   [ matrix_completion, Gaussian random projections, Random Forest ],   Ensemble weight: 0.3544492044097264**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**----------------------**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_list': [<models.imputers.matrix_completion object at 0x000001E43863D908>, <models.preprocessors.GaussProjection object at 0x000001E438648CC0>, <models.classifiers.RandomForest object at 0x000001E438648F60>], 'explained': '[ , , *Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.* ]', 'image_name': None, 'classes': None, 'num_stages': 3, 'pipeline_stages': ['imputer', 'preprocessor', 'classifier'], 'name': '[ matrix_completion, Gaussian random projections, Random Forest ]', 'analysis_mode': None, 'analysis_type': None}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**_____________________________________________**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "[ , , *Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.* ]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning:no image_name\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**----------------------**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "***Kernel Report***"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Component 0**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Members: ['XGBoost', 'Gradient Boosting', 'Random Forest', 'Neural Network']**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mat52.       |  value  |  constraints  |  priors\n",
      "  variance     |    1.0  |      +ve      |        \n",
      "  lengthscale  |    1.0  |      +ve      |        \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Component 1**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Members: ['Multinomial Naive Bayes', 'Bernoulli Naive Bayes', 'Bagging', 'Adaboost']**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mat52.       |               value  |  constraints  |  priors\n",
      "  variance     |  0.9999990131977101  |      +ve      |        \n",
      "  lengthscale  |  0.5799796857419405  |      +ve      |        \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Component 2**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\r",
       "**Members: ['Linear SVM', 'KNN', 'Decision Trees', 'Perceptron', 'Logistic Regression', 'Gauss Naive Bayes', 'QDA', 'LDA']**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mat52.       |               value  |  constraints  |  priors\n",
      "  variance     |  1.0330784354351474  |      +ve      |        \n",
      "  lengthscale  |  1.4854067242492952  |      +ve      |        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_score_single_clf': 0.993040805691102,\n",
       " 'ensemble_model_name': ['[ median, Bagging ]',\n",
       "  '[ median, Normalization, GaussianNaiveBayes ]',\n",
       "  '[ matrix_completion, Gaussian random projections, Random Forest ]'],\n",
       " 'ensemble_model_weight': [0.5013969581075489,\n",
       "  0.14415383748272464,\n",
       "  0.3544492044097264],\n",
       " 'ensemble_score': 0.9940387322357569,\n",
       " 'hyperparameter_properties': [{'name': 'missForest'},\n",
       "  {'name': 'PCA'},\n",
       "  {'hyperparameters': {'model': 'BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\\n                  max_features=1.0, max_samples=0.1378951280696428,\\n                  n_estimators=4080, n_jobs=None, oob_score=False,\\n                  random_state=None, verbose=0, warm_start=False)'},\n",
       "   'name': 'Bagging'}],\n",
       " 'kernel_members': {0: ['XGBoost',\n",
       "   'Gradient Boosting',\n",
       "   'Random Forest',\n",
       "   'Neural Network'],\n",
       "  1: ['Multinomial Naive Bayes',\n",
       "   'Bernoulli Naive Bayes',\n",
       "   'Bagging',\n",
       "   'Adaboost'],\n",
       "  2: ['Linear SVM',\n",
       "   'KNN',\n",
       "   'Decision Trees',\n",
       "   'Perceptron',\n",
       "   'Logistic Regression',\n",
       "   'Gauss Naive Bayes',\n",
       "   'QDA',\n",
       "   'LDA']},\n",
       " 'model_name_single_clf': '[ missForest, PCA, Bagging ]',\n",
       " 'optimisation_metric': 'aucprc'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP_mdl.APReport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "state": {
    "545c66a4cef9492aa833cbb914e8a1c4": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
